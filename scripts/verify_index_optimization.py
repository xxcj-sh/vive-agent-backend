"""
æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–éªŒè¯æŠ¥å‘Š
"""

import logging
from datetime import datetime
from sqlalchemy import text, create_engine
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append('/Users/liukun/Documents/workspace/codebase/VMatch/vive-agent-backend')

from app.config import settings

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def generate_index_optimization_report():
    """ç”Ÿæˆç´¢å¼•ä¼˜åŒ–æŠ¥å‘Š"""
    
    engine = create_engine(settings.computed_database_url)
    
    report = []
    report.append("=" * 80)
    report.append("æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–éªŒè¯æŠ¥å‘Š")
    report.append("=" * 80)
    report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append("")
    
    with engine.connect() as conn:
        try:
            # 1. åˆ†æè¡¨å¤§å°
            report.append("ğŸ“Š æ•°æ®åº“è¡¨å¤§å°åˆ†æ")
            report.append("-" * 50)
            
            result = conn.execute(text("""
                SELECT 
                    table_name,
                    table_rows,
                    ROUND(data_length / 1024 / 1024, 2) as data_mb,
                    ROUND(index_length / 1024 / 1024, 2) as index_mb,
                    ROUND((data_length + index_length) / 1024 / 1024, 2) as total_mb
                FROM information_schema.tables 
                WHERE table_schema = DATABASE()
                ORDER BY total_mb DESC
            """))
            
            tables = result.fetchall()
            
            total_size = 0
            total_indexes = 0
            
            for table in tables:
                table_name = table[0]
                rows = table[1] or 0
                data_mb = table[2] or 0
                index_mb = table[3] or 0
                total_mb = table[4] or 0
                
                total_size += total_mb
                total_indexes += index_mb
                
                report.append(f"è¡¨: {table_name}")
                report.append(f"  è¡Œæ•°: {rows:,}")
                report.append(f"  æ•°æ®: {data_mb:.2f} MB")
                report.append(f"  ç´¢å¼•: {index_mb:.2f} MB")
                report.append(f"  æ€»è®¡: {total_mb:.2f} MB")
                report.append("")
            
            report.append(f"æ•°æ®åº“æ€»å¤§å°: {total_size:.2f} MB")
            report.append(f"ç´¢å¼•æ€»å¤§å°: {total_indexes:.2f} MB")
            report.append(f"ç´¢å¼•å æ¯”: {(total_indexes/total_size*100):.1f}%")
            report.append("")
            
            # 2. åˆ†æç´¢å¼•åˆ›å»ºæƒ…å†µ
            report.append("ğŸ” æ€§èƒ½ä¼˜åŒ–ç´¢å¼•åˆ›å»ºæƒ…å†µ")
            report.append("-" * 50)
            
            # æˆ‘ä»¬åˆ›å»ºçš„æ€§èƒ½ä¼˜åŒ–ç´¢å¼•åˆ—è¡¨
            performance_indexes = {
                'users': ['idx_users_wechat_openid', 'idx_users_status_created'],
                'user_cards': ['idx_user_cards_user_scene_role', 'idx_user_cards_public_list', 'idx_user_cards_scene_type', 'idx_user_cards_search_code'],
                'topic_cards': ['idx_topic_cards_user_status', 'idx_topic_cards_category', 'idx_topic_cards_visibility', 'idx_topic_cards_popularity'],
                'vote_cards': ['idx_vote_cards_user_status', 'idx_vote_cards_category', 'idx_vote_cards_features'],
                'matches': ['idx_matches_user_type_status', 'idx_matches_type_status', 'idx_matches_score'],
                'user_connections': ['idx_user_connections_from_user', 'idx_user_connections_to_user', 'idx_user_connections_unique'],
                'chat_messages': ['idx_chat_messages_user_time', 'idx_chat_messages_card_time', 'idx_chat_messages_session_time', 'idx_chat_messages_type_sender'],
                'topic_discussions': ['idx_topic_discussions_card_time', 'idx_topic_discussions_participant_time', 'idx_topic_discussions_host_time'],
                'vote_records': ['idx_vote_records_user_vote', 'idx_vote_records_option_time', 'idx_vote_records_vote_card_time'],
                'topic_opinion_summaries': ['idx_opinion_summaries_user_topic', 'idx_opinion_summaries_topic_time'],
                'user_card_topic_relations': ['idx_user_card_topic_relations_card', 'idx_user_card_topic_relations_topic'],
                'user_card_vote_relations': ['idx_user_card_vote_relations_card', 'idx_user_card_vote_relations_vote']
            }
            
            created_count = 0
            failed_count = 0
            
            for table, expected_indexes in performance_indexes.items():
                try:
                    # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                    result = conn.execute(text(f"SHOW TABLES LIKE '{table}'"))
                    if not result.fetchone():
                        report.append(f"âš ï¸ è¡¨ {table} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                        continue
                    
                    # è·å–å®é™…ç´¢å¼•
                    result = conn.execute(text(f"""
                        SELECT INDEX_NAME
                        FROM INFORMATION_SCHEMA.STATISTICS 
                        WHERE TABLE_SCHEMA = DATABASE() 
                        AND TABLE_NAME = '{table}'
                    """))
                    
                    actual_indexes = [row[0] for row in result.fetchall()]
                    
                    report.append(f"\nè¡¨: {table}")
                    
                    for expected_idx in expected_indexes:
                        if expected_idx in actual_indexes:
                            report.append(f"  âœ… {expected_idx} - å·²åˆ›å»º")
                            created_count += 1
                        else:
                            report.append(f"  âŒ {expected_idx} - æœªåˆ›å»º")
                            failed_count += 1
                    
                except Exception as e:
                    report.append(f"  âš ï¸ åˆ†æè¡¨ {table} å¤±è´¥: {str(e)}")
            
            report.append(f"\nğŸ“ˆ ç´¢å¼•åˆ›å»ºç»Ÿè®¡:")
            report.append(f"  æˆåŠŸåˆ›å»º: {created_count} ä¸ª")
            report.append(f"  åˆ›å»ºå¤±è´¥: {failed_count} ä¸ª")
            report.append(f"  æˆåŠŸç‡: {((created_count/(created_count+failed_count))*100):.1f}%")
            report.append("")
            
            # 3. åˆ†æç´¢å¼•æ•ˆç‡
            report.append("âš¡ ç´¢å¼•æ•ˆç‡åˆ†æ")
            report.append("-" * 50)
            
            # è·å–è¡¨è¡Œæ•°
            result = conn.execute(text("""
                SELECT 
                    table_name,
                    table_rows
                FROM information_schema.tables 
                WHERE table_schema = DATABASE()
            """))
            
            table_rows = dict(result.fetchall())
            
            # åˆ†ææ¯ä¸ªè¡¨çš„ç´¢å¼•æ•ˆç‡
            for table in performance_indexes.keys():
                try:
                    # è·å–ç´¢å¼•ä¿¡æ¯
                    result = conn.execute(text(f"""
                        SELECT 
                            INDEX_NAME,
                            COLUMN_NAME,
                            CARDINALITY,
                            NON_UNIQUE
                        FROM INFORMATION_SCHEMA.STATISTICS 
                        WHERE TABLE_SCHEMA = DATABASE() 
                        AND TABLE_NAME = '{table}'
                        AND INDEX_NAME IN ({','.join([f"'{idx}'" for idx in performance_indexes[table]])})
                        ORDER BY INDEX_NAME, SEQ_IN_INDEX
                    """))
                    
                    indexes_info = result.fetchall()
                    
                    if indexes_info:
                        rows = table_rows.get(table, 0)
                        report.append(f"\nè¡¨: {table} (è¡Œæ•°: {rows:,})")
                        
                        current_index = ""
                        for idx_info in indexes_info:
                            index_name = idx_info[0]
                            column_name = idx_info[1]
                            cardinality = idx_info[2] or 0
                            
                            if index_name != current_index:
                                current_index = index_name
                                selectivity = (cardinality / rows * 100) if rows > 0 else 0
                                efficiency = "é«˜" if selectivity > 80 else "ä¸­" if selectivity > 30 else "ä½"
                                
                                report.append(f"  ç´¢å¼•: {index_name}")
                                report.append(f"    åˆ—: {column_name}")
                                report.append(f"    åŸºæ•°: {cardinality:,}")
                                report.append(f"    é€‰æ‹©æ€§: {selectivity:.2f}%")
                                report.append(f"    æ•ˆç‡: {efficiency}")
                                report.append("")
                
                except Exception as e:
                    report.append(f"  âš ï¸ åˆ†æç´¢å¼•æ•ˆç‡å¤±è´¥ - {table}: {str(e)}")
            
            # 4. æŸ¥è¯¢æ€§èƒ½å»ºè®®
            report.append("ğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®")
            report.append("-" * 50)
            report.append("åŸºäºç´¢å¼•åˆ†æï¼Œæä¾›ä»¥ä¸‹å»ºè®®ï¼š")
            report.append("")
            report.append("1. ç´¢å¼•åˆ›å»ºå»ºè®®:")
            report.append("   - å·²æˆåŠŸåˆ›å»ºå¤§éƒ¨åˆ†æ€§èƒ½ä¼˜åŒ–ç´¢å¼•")
            report.append("   - éƒ¨åˆ†ç´¢å¼•åˆ›å»ºå¤±è´¥ï¼Œå¯èƒ½æ˜¯å› ä¸ºè¡¨ä¸å­˜åœ¨æˆ–è¯­æ³•å…¼å®¹æ€§é—®é¢˜")
            report.append("   - å»ºè®®æ£€æŸ¥å¤±è´¥åŸå› å¹¶æ‰‹åŠ¨åˆ›å»ºé‡è¦ç´¢å¼•")
            report.append("")
            report.append("2. ç´¢å¼•ç»´æŠ¤å»ºè®®:")
            report.append("   - å®šæœŸæ›´æ–°è¡¨ç»Ÿè®¡ä¿¡æ¯: ANALYZE TABLE")
            report.append("   - ç›‘æ§ç´¢å¼•ä½¿ç”¨æƒ…å†µï¼Œåˆ é™¤æœªä½¿ç”¨çš„ç´¢å¼•")
            report.append("   - å¯¹äºé€‰æ‹©æ€§ä½çš„ç´¢å¼•ï¼Œè€ƒè™‘è°ƒæ•´åˆ—é¡ºåºæˆ–åˆ é™¤")
            report.append("")
            report.append("3. æŸ¥è¯¢ä¼˜åŒ–å»ºè®®:")
            report.append("   - ç¡®ä¿æŸ¥è¯¢è¯­å¥ä½¿ç”¨åˆ›å»ºçš„å¤åˆç´¢å¼•")
            report.append("   - é¿å…åœ¨ç´¢å¼•åˆ—ä¸Šä½¿ç”¨å‡½æ•°æˆ–è¡¨è¾¾å¼")
            report.append("   - å¯¹äºå¤§è¡¨æŸ¥è¯¢ï¼Œç¡®ä¿WHEREæ¡ä»¶åŒ¹é…ç´¢å¼•å‰ç¼€")
            report.append("")
            report.append("4. ç›‘æ§å»ºè®®:")
            report.append("   - å¯ç”¨MySQLæ…¢æŸ¥è¯¢æ—¥å¿—ç›‘æ§æ…¢æŸ¥è¯¢")
            report.append("   - å®šæœŸæ£€æŸ¥ç´¢å¼•ç¢ç‰‡ç‡")
            report.append("   - ç›‘æ§æ•°æ®åº“è¿æ¥æ•°å’ŒæŸ¥è¯¢å“åº”æ—¶é—´")
            
        except Exception as e:
            report.append(f"\nâŒ åˆ†æå¤±è´¥: {str(e)}")
        
        finally:
            conn.close()
    
    engine.dispose()
    
    # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
    report_file = f"index_optimization_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report))
    
    logger.info(f"\næŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    return '\n'.join(report)

if __name__ == "__main__":
    logger.info("å¼€å§‹ç”Ÿæˆç´¢å¼•ä¼˜åŒ–éªŒè¯æŠ¥å‘Š...")
    report = generate_index_optimization_report()
    print("\n" + report)